{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Chapter 3: Named Entity Recognition or NER**","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"This is a step in NLP that is used to identify named entities in a corpus. \nThis might include things such as:\n1. People, organizations, places\n2. Dates, states\n3. Work of arts and other categories\n\nThere are a number of libraries that one can use for NER, among them:\n* Stanford coreNLP\n* NLTK\n* SpaCy","metadata":{}},{"cell_type":"markdown","source":"In short:\n> Named Entity Recognition (NER) is a crucial task in natural language processing that helps identify important entities in texts, such as people, places, organizations, dates, and more. This capability is vital for extracting information, answering basic questions, and analyzing text content. Key points covered include:\n>\n> Understanding NER: Mostly, NER works to highlight and categorize parts of the text into predefined categories like persons, locations, and organizations using libraries like NLTK and Stanford NER.\n>\n> \n**Practical Application with NLTK: One can practice NER using nltk, starting with tokenizing texts into sentences and words, tagging each word for its part of speech, and then chunking these into named entities. For example:**\n\nIn this chapter, we aim to learn how to chart the diversity of named entity types in texts, using tools like *defaultdict* to categorize and count occurrences of each entity type.\n","metadata":{}},{"cell_type":"markdown","source":"## **NER with NLTK**","metadata":{}},{"cell_type":"markdown","source":"   \n>  Tokenize article into sentences.\n>\n> Tokenize each sentence in sentences into words using a list comprehension.\n>\n> Inside a list comprehension, tag each tokenized sentence into parts of speech using nltk.pos_tag().\n>\n> Chunk each tagged sentence into named-entity chunks using nltk.ne_chunk_sents().\n>\n> Along with pos_sentences, specify the additional keyword argument binary=True.\n>\n> Loop over each sentence and each chunk, and test whether it is a named-entity chunk by testing if it has the attribute label, and if the chunk.label() is equal to \"NE\". If so, print that chunk.\n\n","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk import pos_tag                   #to tag the part of a tokenized sentences\n\nfrom nltk.chunk import ne_chunk_sents    \n\n\narticles = \"\"\"'The taxi-hailing company Uber brings into very sharp focus the question of whether corporations can be said to\nhave a moral character. \nIf any human being were to behave with the single-minded and ruthless greed of the company, \nwe would consider them sociopathic. Uber wanted to know as much as possible about the people who use its service, \nand those who don’t. It has an arrangement with unroll.me, a company which offered a free service for unsubscribing from junk mail, \nto buy the contacts unroll.me customers had had with rival taxi companies. Even if their email was notionally anonymised, \nthis use of it was not something the users had bargained for. \nBeyond that, it keeps track of the phones that have been used to summon its services even after the original owner has sold them, \nattempting this with Apple’s phones even thought it is forbidden by the company.\\r\\n\\r\\n\\r\\nUber has also tweaked its software so that regulatory agencies that the company regarded as hostile would, when they tried to hire a driver, be given false reports about the location of its cars. Uber management booked and then cancelled rides with a rival taxi-hailing company which took their vehicles out of circulation. Uber deny this was the intention. The punishment for this behaviour was negligible. Uber promised not to use this “greyball” software against law enforcement – one wonders what would happen to someone carrying a knife who promised never to stab a policeman with it. Travis Kalanick of Uber got a personal dressing down from Tim Cook, who runs Apple, but the company did not prohibit the use of the app. Too much money was at stake for that.\\r\\n\\r\\n\\r\\nMillions of people around the world value the cheapness and convenience of Uber’s rides too much to care about the lack of drivers’ rights or pay. Many of the users themselves are not much richer than the drivers. The “sharing economy” encourages the insecure and exploited to exploit others equally insecure to the profit of a tiny clique of billionaires. Silicon Valley’s culture seems hostile to humane and democratic values. The outgoing CEO of Yahoo, Marissa Mayer, who is widely judged to have been a failure, is likely to get a $186m payout. This may not be a cause for panic, any more than the previous hero worship should have been a cause for euphoria. Yet there’s an urgent political task to tame these companies, to ensure they are punished when they break the law, \nthat they pay their taxes fairly and that they behave responsibly.\"\"\"\n\n# Tokenize the article into sentences: sentences\nsentences = sent_tokenize(articles)\n\n# Tokenize each sentence into words: token_sentences\ntoken_sentences = [word_tokenize(sent) for sent in sentences]\n\n# Tag each tokenized sentence into parts of speech: pos_sentences\npos_sentences = [pos_tag(sent) for sent in token_sentences] \nprint(pos_sentences)\n\n# Create the named entity chunks: chunked_sentences\nchunked_sentences = ne_chunk_sents(pos_sentences, binary = True)\n\n\n# Test for stems of the tree with 'NE' tags\nfor sent in chunked_sentences:\n    for chunk in sent:\n        if hasattr(chunk, \"label\") and chunk.label() == \"NE\":\n            print(chunk)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T11:34:06.438741Z","iopub.execute_input":"2024-11-06T11:34:06.439227Z","iopub.status.idle":"2024-11-06T11:34:08.506279Z","shell.execute_reply.started":"2024-11-06T11:34:06.439180Z","shell.execute_reply":"2024-11-06T11:34:08.504931Z"}},"outputs":[{"name":"stdout","text":"[[(\"'The\", 'POS'), ('taxi-hailing', 'JJ'), ('company', 'NN'), ('Uber', 'NNP'), ('brings', 'VBZ'), ('into', 'IN'), ('very', 'RB'), ('sharp', 'JJ'), ('focus', 'VB'), ('the', 'DT'), ('question', 'NN'), ('of', 'IN'), ('whether', 'IN'), ('corporations', 'NNS'), ('can', 'MD'), ('be', 'VB'), ('said', 'VBD'), ('to', 'TO'), ('have', 'VB'), ('a', 'DT'), ('moral', 'JJ'), ('character', 'NN'), ('.', '.')], [('If', 'IN'), ('any', 'DT'), ('human', 'JJ'), ('being', 'VBG'), ('were', 'VBD'), ('to', 'TO'), ('behave', 'VB'), ('with', 'IN'), ('the', 'DT'), ('single-minded', 'JJ'), ('and', 'CC'), ('ruthless', 'JJ'), ('greed', 'NN'), ('of', 'IN'), ('the', 'DT'), ('company', 'NN'), (',', ','), ('we', 'PRP'), ('would', 'MD'), ('consider', 'VB'), ('them', 'PRP'), ('sociopathic', 'JJ'), ('.', '.')], [('Uber', 'NNP'), ('wanted', 'VBD'), ('to', 'TO'), ('know', 'VB'), ('as', 'RB'), ('much', 'JJ'), ('as', 'IN'), ('possible', 'JJ'), ('about', 'IN'), ('the', 'DT'), ('people', 'NNS'), ('who', 'WP'), ('use', 'VBP'), ('its', 'PRP$'), ('service', 'NN'), (',', ','), ('and', 'CC'), ('those', 'DT'), ('who', 'WP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NN'), ('.', '.')], [('It', 'PRP'), ('has', 'VBZ'), ('an', 'DT'), ('arrangement', 'NN'), ('with', 'IN'), ('unroll.me', 'JJ'), (',', ','), ('a', 'DT'), ('company', 'NN'), ('which', 'WDT'), ('offered', 'VBD'), ('a', 'DT'), ('free', 'JJ'), ('service', 'NN'), ('for', 'IN'), ('unsubscribing', 'VBG'), ('from', 'IN'), ('junk', 'NN'), ('mail', 'NN'), (',', ','), ('to', 'TO'), ('buy', 'VB'), ('the', 'DT'), ('contacts', 'NNS'), ('unroll.me', 'JJ'), ('customers', 'NNS'), ('had', 'VBD'), ('had', 'VBN'), ('with', 'IN'), ('rival', 'JJ'), ('taxi', 'NN'), ('companies', 'NNS'), ('.', '.')], [('Even', 'RB'), ('if', 'IN'), ('their', 'PRP$'), ('email', 'NN'), ('was', 'VBD'), ('notionally', 'RB'), ('anonymised', 'VBN'), (',', ','), ('this', 'DT'), ('use', 'NN'), ('of', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('not', 'RB'), ('something', 'NN'), ('the', 'DT'), ('users', 'NNS'), ('had', 'VBD'), ('bargained', 'VBN'), ('for', 'IN'), ('.', '.')], [('Beyond', 'NN'), ('that', 'IN'), (',', ','), ('it', 'PRP'), ('keeps', 'VBZ'), ('track', 'NN'), ('of', 'IN'), ('the', 'DT'), ('phones', 'NNS'), ('that', 'WDT'), ('have', 'VBP'), ('been', 'VBN'), ('used', 'VBN'), ('to', 'TO'), ('summon', 'VB'), ('its', 'PRP$'), ('services', 'NNS'), ('even', 'RB'), ('after', 'IN'), ('the', 'DT'), ('original', 'JJ'), ('owner', 'NN'), ('has', 'VBZ'), ('sold', 'VBN'), ('them', 'PRP'), (',', ','), ('attempting', 'VBG'), ('this', 'DT'), ('with', 'IN'), ('Apple', 'NNP'), ('’', 'NNP'), ('s', 'VBP'), ('phones', 'NNS'), ('even', 'RB'), ('thought', 'VBD'), ('it', 'PRP'), ('is', 'VBZ'), ('forbidden', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('company', 'NN'), ('.', '.')], [('Uber', 'NNP'), ('has', 'VBZ'), ('also', 'RB'), ('tweaked', 'VBN'), ('its', 'PRP$'), ('software', 'NN'), ('so', 'IN'), ('that', 'DT'), ('regulatory', 'JJ'), ('agencies', 'NNS'), ('that', 'IN'), ('the', 'DT'), ('company', 'NN'), ('regarded', 'VBD'), ('as', 'IN'), ('hostile', 'NN'), ('would', 'MD'), (',', ','), ('when', 'WRB'), ('they', 'PRP'), ('tried', 'VBD'), ('to', 'TO'), ('hire', 'VB'), ('a', 'DT'), ('driver', 'NN'), (',', ','), ('be', 'VB'), ('given', 'VBN'), ('false', 'JJ'), ('reports', 'NNS'), ('about', 'IN'), ('the', 'DT'), ('location', 'NN'), ('of', 'IN'), ('its', 'PRP$'), ('cars', 'NNS'), ('.', '.')], [('Uber', 'NNP'), ('management', 'NN'), ('booked', 'VBD'), ('and', 'CC'), ('then', 'RB'), ('cancelled', 'VBD'), ('rides', 'NNS'), ('with', 'IN'), ('a', 'DT'), ('rival', 'JJ'), ('taxi-hailing', 'JJ'), ('company', 'NN'), ('which', 'WDT'), ('took', 'VBD'), ('their', 'PRP$'), ('vehicles', 'NNS'), ('out', 'IN'), ('of', 'IN'), ('circulation', 'NN'), ('.', '.')], [('Uber', 'NNP'), ('deny', 'NN'), ('this', 'DT'), ('was', 'VBD'), ('the', 'DT'), ('intention', 'NN'), ('.', '.')], [('The', 'DT'), ('punishment', 'NN'), ('for', 'IN'), ('this', 'DT'), ('behaviour', 'NN'), ('was', 'VBD'), ('negligible', 'JJ'), ('.', '.')], [('Uber', 'NNP'), ('promised', 'VBD'), ('not', 'RB'), ('to', 'TO'), ('use', 'VB'), ('this', 'DT'), ('“', 'NN'), ('greyball', 'NN'), ('”', 'NNP'), ('software', 'NN'), ('against', 'IN'), ('law', 'NN'), ('enforcement', 'NN'), ('–', 'NNP'), ('one', 'NN'), ('wonders', 'VBZ'), ('what', 'WDT'), ('would', 'MD'), ('happen', 'VB'), ('to', 'TO'), ('someone', 'NN'), ('carrying', 'VBG'), ('a', 'DT'), ('knife', 'NN'), ('who', 'WP'), ('promised', 'VBD'), ('never', 'RB'), ('to', 'TO'), ('stab', 'VB'), ('a', 'DT'), ('policeman', 'NN'), ('with', 'IN'), ('it', 'PRP'), ('.', '.')], [('Travis', 'NNP'), ('Kalanick', 'NNP'), ('of', 'IN'), ('Uber', 'NNP'), ('got', 'VBD'), ('a', 'DT'), ('personal', 'JJ'), ('dressing', 'VBG'), ('down', 'RP'), ('from', 'IN'), ('Tim', 'NNP'), ('Cook', 'NNP'), (',', ','), ('who', 'WP'), ('runs', 'VBZ'), ('Apple', 'NNP'), (',', ','), ('but', 'CC'), ('the', 'DT'), ('company', 'NN'), ('did', 'VBD'), ('not', 'RB'), ('prohibit', 'VB'), ('the', 'DT'), ('use', 'NN'), ('of', 'IN'), ('the', 'DT'), ('app', 'NN'), ('.', '.')], [('Too', 'RB'), ('much', 'JJ'), ('money', 'NN'), ('was', 'VBD'), ('at', 'IN'), ('stake', 'NN'), ('for', 'IN'), ('that', 'DT'), ('.', '.')], [('Millions', 'NNS'), ('of', 'IN'), ('people', 'NNS'), ('around', 'IN'), ('the', 'DT'), ('world', 'NN'), ('value', 'NN'), ('the', 'DT'), ('cheapness', 'NN'), ('and', 'CC'), ('convenience', 'NN'), ('of', 'IN'), ('Uber', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('rides', 'NNS'), ('too', 'RB'), ('much', 'RB'), ('to', 'TO'), ('care', 'VB'), ('about', 'IN'), ('the', 'DT'), ('lack', 'NN'), ('of', 'IN'), ('drivers', 'NNS'), ('’', 'NNP'), ('rights', 'NNS'), ('or', 'CC'), ('pay', 'NN'), ('.', '.')], [('Many', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('users', 'NNS'), ('themselves', 'PRP'), ('are', 'VBP'), ('not', 'RB'), ('much', 'RB'), ('richer', 'JJR'), ('than', 'IN'), ('the', 'DT'), ('drivers', 'NNS'), ('.', '.')], [('The', 'DT'), ('“', 'JJ'), ('sharing', 'VBG'), ('economy', 'NN'), ('”', 'JJ'), ('encourages', 'VBZ'), ('the', 'DT'), ('insecure', 'NN'), ('and', 'CC'), ('exploited', 'VBD'), ('to', 'TO'), ('exploit', 'VB'), ('others', 'NNS'), ('equally', 'RB'), ('insecure', 'VBP'), ('to', 'TO'), ('the', 'DT'), ('profit', 'NN'), ('of', 'IN'), ('a', 'DT'), ('tiny', 'JJ'), ('clique', 'NN'), ('of', 'IN'), ('billionaires', 'NNS'), ('.', '.')], [('Silicon', 'NNP'), ('Valley', 'NNP'), ('’', 'NNP'), ('s', 'JJ'), ('culture', 'NN'), ('seems', 'VBZ'), ('hostile', 'JJ'), ('to', 'TO'), ('humane', 'NN'), ('and', 'CC'), ('democratic', 'JJ'), ('values', 'NNS'), ('.', '.')], [('The', 'DT'), ('outgoing', 'VBG'), ('CEO', 'NNP'), ('of', 'IN'), ('Yahoo', 'NNP'), (',', ','), ('Marissa', 'NNP'), ('Mayer', 'NNP'), (',', ','), ('who', 'WP'), ('is', 'VBZ'), ('widely', 'RB'), ('judged', 'VBN'), ('to', 'TO'), ('have', 'VB'), ('been', 'VBN'), ('a', 'DT'), ('failure', 'NN'), (',', ','), ('is', 'VBZ'), ('likely', 'JJ'), ('to', 'TO'), ('get', 'VB'), ('a', 'DT'), ('$', '$'), ('186m', 'CD'), ('payout', 'NN'), ('.', '.')], [('This', 'DT'), ('may', 'MD'), ('not', 'RB'), ('be', 'VB'), ('a', 'DT'), ('cause', 'NN'), ('for', 'IN'), ('panic', 'NN'), (',', ','), ('any', 'DT'), ('more', 'JJR'), ('than', 'IN'), ('the', 'DT'), ('previous', 'JJ'), ('hero', 'NN'), ('worship', 'NN'), ('should', 'MD'), ('have', 'VB'), ('been', 'VBN'), ('a', 'DT'), ('cause', 'NN'), ('for', 'IN'), ('euphoria', 'NN'), ('.', '.')], [('Yet', 'RB'), ('there', 'EX'), ('’', 'NNP'), ('s', 'VBD'), ('an', 'DT'), ('urgent', 'JJ'), ('political', 'JJ'), ('task', 'NN'), ('to', 'TO'), ('tame', 'VB'), ('these', 'DT'), ('companies', 'NNS'), (',', ','), ('to', 'TO'), ('ensure', 'VB'), ('they', 'PRP'), ('are', 'VBP'), ('punished', 'VBN'), ('when', 'WRB'), ('they', 'PRP'), ('break', 'VBP'), ('the', 'DT'), ('law', 'NN'), (',', ','), ('that', 'IN'), ('they', 'PRP'), ('pay', 'VBP'), ('their', 'PRP$'), ('taxes', 'NNS'), ('fairly', 'RB'), ('and', 'CC'), ('that', 'IN'), ('they', 'PRP'), ('behave', 'VBP'), ('responsibly', 'RB'), ('.', '.')]]\n(NE Uber/NNP)\n(NE Beyond/NN)\n(NE Apple/NNP)\n(NE Uber/NNP)\n(NE Uber/NNP)\n(NE Travis/NNP Kalanick/NNP)\n(NE Tim/NNP Cook/NNP)\n(NE Apple/NNP)\n(NE Silicon/NNP Valley/NNP)\n(NE CEO/NNP)\n(NE Yahoo/NNP)\n(NE Marissa/NNP Mayer/NNP)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### **Charting practice**\n\n","metadata":{}},{"cell_type":"markdown","source":"\n> In this exercise, you'll use some extracted named entities and their groupings from a series of newspaper articles to chart the diversity of named entity types in the articles.\n>\n> You'll use a defaultdict called ner_categories, with keys representing every named entity group type, and values to count the number of each different named entity type.\n>\n> You have a chunked sentence list called chunked_sentences similar to the last exercise, but this time with non-binary category names.You can use hasattr() to determine if each chunk has a 'label' and then simply use the chunk's .label() method as the dictionary key.\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"\n   \n>  Fill up the dictionary with values for each of the keys. Remember, the keys will represent the label().        In the outer for loop, iterate over chunked_sentences, using sent as your iterator variable.\n>\n> In the inner for loop, iterate over sent.\n>\n> If the condition is true, increment the value of each key by 1.\n>\n> Remember to use the chunk's .label() method as the key!    For the pie chart labels, create a list called labels from the keys of ner_categories, which can be accessed using .keys().\n","metadata":{}},{"cell_type":"markdown","source":"\n   \n>  Use a list comprehension to create a list called values, using the .get() method on ner_categories to compute the values of each label v.\n>\n>  Use plt.pie() to create a pie chart for each of the NER categories. Along with values and labels=labels, pass the extra keyword arguments autopct='%1.1f%%' and startangle=140 to add percentages to the chart and rotate the initial start angle.\n>\n> This step has been done for you.    Display your pie chart. Was the distribution what you expected?\n","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\nfrom matplotlib import pyplot as plt\n# Create the defaultdict: ner_categories\nner_categories = defaultdict(int)\n\n# Create the nested for loop\nfor sent in chunked_sentences:\n    for chunk in sent:\n        if hasattr(chunk, 'label'):\n            ner_categories[chunk.label()] += 1\n            \n# Create a list from the dictionary keys for the chart labels: labels\nlabels = list(ner_categories.keys())\n\n# Create a list of the values: values\nvalues = [ner_categories.get(v) for v in labels]\n\n# Create the pie chart\nplt.pie(values, labels=labels, autopct='%1.1f%%', startangle=140)\n\n# Display the chart\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:24:50.576566Z","iopub.execute_input":"2024-11-07T00:24:50.577719Z","iopub.status.idle":"2024-11-07T00:24:51.016355Z","shell.execute_reply.started":"2024-11-07T00:24:50.577665Z","shell.execute_reply":"2024-11-07T00:24:51.014658Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m ner_categories \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create the nested for loop\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchunked_sentences\u001b[49m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m sent:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(chunk, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","\u001b[0;31mNameError\u001b[0m: name 'chunked_sentences' is not defined"],"ename":"NameError","evalue":"name 'chunked_sentences' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## **Introduction to SpaCy**","metadata":{}},{"cell_type":"markdown","source":"SpaCy is another great library for NLP. It is very similar to Gensim,but with different implementation.\n\n**To use SpaCy, we must first install it and also download all appropriate pre-trained word vectors.**\n\n**It is a great tool for building NLP pipeline quickly and iteratively.** \n\n*NOTE: unlike NLTK, it has incorporates informal language corpora, making it easy to deal with things like tweets and chat messages.*","metadata":{}},{"cell_type":"markdown","source":"* First, call the load method to initialize the NLP task, pass this to the nlp object\n* Load a document into this\n* When the document is loaded, the named entities are stored as document attributes called \"ents\"","metadata":{}},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load('en_core_web_sm')              # This is similar to Gensim Dictionary or corpus. It has several linked objects\n\n# Some linkes objects\n#nlp.pipeline.\ndoc = nlp(\"\"\"The United States Forest Service (USFS) is an agency within the U.S. Department of Agriculture \nthat administers the nation's 154 national forests and 20 national grasslands covering 193 million acres (780,000 km2) of land.[5] \nThe major divisions of the agency are the Chief's Office, National Forest System, State and Private Forestry, Business Operations, \nas well as Research and Development.[6] \nThe agency manages about 25% of federal lands and is the sole major national land management \nagency not part of the U.S. Department of the Interior[7] \n(which manages the National Park Service, the U.S. Fish and Wildlife Service and the Bureau of Land Management). \"\"\")\n\ndoc.ents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:37:55.478059Z","iopub.execute_input":"2024-11-07T00:37:55.478554Z","iopub.status.idle":"2024-11-07T00:37:56.793750Z","shell.execute_reply.started":"2024-11-07T00:37:55.478510Z","shell.execute_reply":"2024-11-07T00:37:56.792254Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(The United States Forest Service,\n USFS,\n the U.S. Department of Agriculture,\n 154,\n 20,\n 193 million acres,\n 780,000,\n the Chief's Office,\n National Forest System,\n State,\n Private Forestry, Business Operations,\n Research,\n about 25%,\n the U.S. Department,\n the National Park Service,\n the U.S. Fish and Wildlife Service,\n the Bureau of Land Management)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"The labels for each entity can be observed using **indiexing**, the label for each entity can be found using the **label_** attribute.\n","metadata":{}},{"cell_type":"code","source":"print(doc.ents[0], doc.ents[0].label_)\n[entity.label_ for entity in doc.ents]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T00:54:49.154195Z","iopub.execute_input":"2024-11-07T00:54:49.154639Z","iopub.status.idle":"2024-11-07T00:54:49.164542Z","shell.execute_reply.started":"2024-11-07T00:54:49.154600Z","shell.execute_reply":"2024-11-07T00:54:49.163291Z"}},"outputs":[{"name":"stdout","text":"The United States Forest Service ORG\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"['ORG',\n 'ORG',\n 'ORG',\n 'CARDINAL',\n 'CARDINAL',\n 'QUANTITY',\n 'CARDINAL',\n 'ORG',\n 'ORG',\n 'ORG',\n 'ORG',\n 'ORG',\n 'PERCENT',\n 'ORG',\n 'ORG',\n 'ORG',\n 'ORG']"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"#### **Exercise: Comparing NLTK with spaCy NER**","metadata":{}},{"cell_type":"markdown","source":"\n> Using the same text you used in the first exercise of this chapter, you'll now see the results using spaCy's NER annotator.\n>\n> How will they compare?The article has been pre-loaded as article. To minimize execution times, you'll be asked to specify the keyword argument disable=['tagger', 'parser', 'matcher'] when loading the spaCy model, because you only care about the entity in this exercise.\n","metadata":{}},{"cell_type":"code","source":"# Instantiate the English model: nlp\nnlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'matcher'])\n\narticle = \"\"\"'The taxi-hailing company Uber brings into very sharp focus the question of whether corporations can be said to\nhave a moral character. \nIf any human being were to behave with the single-minded and ruthless greed of the company, \nwe would consider them sociopathic. Uber wanted to know as much as possible about the people who use its service, \nand those who don’t. It has an arrangement with unroll.me, a company which offered a free service for unsubscribing from junk mail, \nto buy the contacts unroll.me customers had had with rival taxi companies. Even if their email was notionally anonymised, \nthis use of it was not something the users had bargained for. \nBeyond that, it keeps track of the phones that have been used to summon its services even after the original owner has sold them, \nattempting this with Apple’s phones even thought it is forbidden by the company.\\r\\n\\r\\n\\r\\nUber has also tweaked its software so that regulatory agencies that the company regarded as hostile would, when they tried to hire a driver, be given false reports about the location of its cars. Uber management booked and then cancelled rides with a rival taxi-hailing company which took their vehicles out of circulation. Uber deny this was the intention. The punishment for this behaviour was negligible. Uber promised not to use this “greyball” software against law enforcement – one wonders what would happen to someone carrying a knife who promised never to stab a policeman with it. Travis Kalanick of Uber got a personal dressing down from Tim Cook, who runs Apple, but the company did not prohibit the use of the app. Too much money was at stake for that.\\r\\n\\r\\n\\r\\nMillions of people around the world value the cheapness and convenience of Uber’s rides too much to care about the lack of drivers’ rights or pay. Many of the users themselves are not much richer than the drivers. The “sharing economy” encourages the insecure and exploited to exploit others equally insecure to the profit of a tiny clique of billionaires. Silicon Valley’s culture seems hostile to humane and democratic values. The outgoing CEO of Yahoo, Marissa Mayer, who is widely judged to have been a failure, is likely to get a $186m payout. This may not be a cause for panic, any more than the previous hero worship should have been a cause for euphoria. Yet there’s an urgent political task to tame these companies, to ensure they are punished when they break the law, \nthat they pay their taxes fairly and that they behave responsibly.\"\"\"\n\n\n# Create a new document: doc\ndoc = nlp(article)\n\n# Print all of the found entities and their labels\nfor ent in doc.ents:\n    print(ent.label_, ent.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T01:07:32.548683Z","iopub.execute_input":"2024-11-07T01:07:32.549496Z","iopub.status.idle":"2024-11-07T01:07:33.866846Z","shell.execute_reply.started":"2024-11-07T01:07:32.549350Z","shell.execute_reply":"2024-11-07T01:07:33.865703Z"}},"outputs":[{"name":"stdout","text":"ORG Apple\nPERSON Travis Kalanick of Uber\nPERSON Tim Cook\nORG Apple\nLOC Silicon Valley’s\nNORP democratic\nORG Yahoo\nPERSON Marissa Mayer\nMONEY 186\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n  warnings.warn(Warnings.W108)\n","output_type":"stream"}],"execution_count":13}]}